{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea2861ac",
   "metadata": {
    "id": "ea2861ac"
   },
   "source": [
    "<font size=7>Introduction to Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7549c9bf",
   "metadata": {
    "id": "7549c9bf"
   },
   "source": [
    "The perceptron is a machine learning algorithm that is used to make classifications between two different binary outcomes, $\\{-1,1\\}$. It has a rich history in neuroscience and AI. Here's a [video clip](https://www.youtube.com/watch?v=cNxadbrN_aI) of it from the 1950's! Here we provide an introduction to the perceptron algorithm. Later will be adapt the perceptron so that it more closely resembles neurons in the brain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f92a2e",
   "metadata": {
    "id": "a9f92a2e"
   },
   "source": [
    "<font color=\"red\"><b>Note:</b> This homework will be due April 10th at 11:59pm PT.  Make sure to complete the exercises at the bottom of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7bfe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"Perceptron_Source_Code.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8facc9",
   "metadata": {
    "id": "2f8facc9"
   },
   "source": [
    "# <font color=\"gray\">Learn from Reading Material <small>(Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b25a9a",
   "metadata": {
    "id": "04b25a9a"
   },
   "source": [
    "Though we describe the perceptron algorithm here, you should teach it to yourself using the following reading material on perceptrons, linear algebra, and quantum notation. For each topic choose the reading material the works best for you!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0828ea",
   "metadata": {
    "id": "8b0828ea"
   },
   "source": [
    "\n",
    "Read the [wiki article](https://en.wikipedia.org/wiki/Perceptron) and chapter 5 of [Hertz's book](https://drive.google.com/file/d/1oAKsTh2RViRX7zr16o947lIRrYYGneBz/view?usp=share_link) on the perceptron. Here is [a review](https://drive.google.com/file/d/1dUBsUhgOuHGxCcG0dKKzDSH3VG2urKww/view?usp=share_link) of topics in linear algebra. This longer [linear algebra reference (Jordan)](https://drive.google.com/file/d/1DYjgvTvMJmQb1O8LFdZUVT5glUSbmPmO/view?usp=share_link) from the classic book, \"Parallel Distributed Computing\" is particularly focused on the topics we'll be covering. Optionally, if you want to prepare for a generalization of these ideas to quantum mechanics, read the \"mathematical interlude: vector spaces\" in the Chapter 1, section 1.9 of [Susskind's book](https://drive.google.com/file/d/1UDZ_pbzkBfQ_VJ084eVZSJPdLHSSueG0/view?usp=share_link). This is another [simple resource](https://towardsdatascience.com/a-casual-guide-to-dirac-notation-17961670ae7a) that introduces quantum notation. The additional material below  provides a more in depth walkthrough of the perceptron algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7860fe3a",
   "metadata": {
    "id": "7860fe3a"
   },
   "source": [
    "**Reading Material**\n",
    "1. Basic Perceptrons Introduction\n",
    "    * [Preceptron Wikipedia](https://en.wikipedia.org/wiki/Perceptron) - A good introduction\n",
    "    * [This video](https://www.youtube.com/watch?v=NogzKXE74AA) is a nice perceptorn overview. [This video](https://www.youtube.com/watch?v=4Gac5I64LM4) does basic perceptron examples. Feel free to suggest other videos!\n",
    "2. Perceptrons Textbooks\n",
    "     * [Pattern Recognition and Machine Learning, Chapter 3 (Bishop)](https://drive.google.com/file/d/1gUN9FgqRsJTGfzgI8emE0EbNLmLP8am4/view?usp=share_link) - The perceptron is deeply described here. There's also a more general description of binary learning.\n",
    "     * [Theory of Neural Computation, Chapter 5 (Hertz)](https://drive.google.com/file/d/1oAKsTh2RViRX7zr16o947lIRrYYGneBz/view?usp=share_link) - Deep dive into perceptron. Also describes perceptron confidence threshold.\n",
    "2. Linear Algebra Review\n",
    "    * [Parallel Distributed Computing, Chapter 9](https://drive.google.com/file/d/1DYjgvTvMJmQb1O8LFdZUVT5glUSbmPmO/view?usp=share_link) A classic! Describes linear algebra within the context we'll be using it.\n",
    "    * [General review of topics](https://drive.google.com/file/d/1dUBsUhgOuHGxCcG0dKKzDSH3VG2urKww/view?usp=share_link) in Linear Algebra\n",
    "2. Quantum Notation\n",
    "    * [Simple introduction](https://towardsdatascience.com/a-casual-guide-to-dirac-notation-17961670ae7a) to Dirac notation\n",
    "    * [Quantum Mechanics, Chapter 1 (Susskind)](https://drive.google.com/file/d/1UDZ_pbzkBfQ_VJ084eVZSJPdLHSSueG0/view?usp=share_link) - Optionally, read the \"mathematical interlude\" section to learn about bra-ket notation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e67ba2a",
   "metadata": {
    "id": "3e67ba2a"
   },
   "source": [
    "**Advanced Papers**\n",
    "1. [Fundamentals of Artificial Neural Networks (Hassoun)](https://neuron.eng.wayne.edu/tarek/MITbook/t_contents.html)- Chapter 1 covers learning capacity. Chapter 3 gives proof of convergence theorem. \n",
    "1. [Perceptron Learning with Sign-Constrained Weights (Amit)](https://drive.google.com/file/d/17X1m0ItbazDn-c7eQOtoVzpKSWYWsItm/view?usp=share_link)- Introduces framework for biorealistic perceptrons\n",
    "2. [Space of Interactions in Neural Network Models (Gardener)](https://drive.google.com/file/d/1C64mHFJeB_TgXdXSPyyOg2H0tY6mOkLi/view?usp=share_link)- Discusses the information storage capacity of perceptrons\n",
    "3. [Information Capacity of Perceptron vs Purkinje Cell (Brunel)](https://drive.google.com/file/d/1S-9pDKR-9gsdqjmS1LvDnf02QAfgxmEG/view?usp=share_link)- Compares properties of Perceptrons to the Purkinje Cells from which they were derived"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1da780b",
   "metadata": {
    "id": "d1da780b"
   },
   "source": [
    "# What is the Perceptron?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4bf8e5",
   "metadata": {
    "id": "7e4bf8e5"
   },
   "source": [
    "## Linear Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edb1f83",
   "metadata": {
    "cell_style": "center",
    "id": "2edb1f83"
   },
   "source": [
    "Suppose you are given a a bucket of tulips and roses and are told to build a learning algorithm to distinguish tulips from roses based on their petals. For each flower you pluck a petal and measure it's width and length. You then plot the results. Run the code below to see the plot. What rule would you use to classify the flowers? An intuitive way to solve this problem is to draw a line on the plot that seperates tulips from roses. This is called a linear classifier. Use the interactive widgets below to fit a linear classifier to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962df24f",
   "metadata": {
    "cell_style": "center",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416,
     "referenced_widgets": [
      "1a67da76dff0411f8503dc0d63182899",
      "fcfca24ea9b04decb9c785ba7a838922",
      "b8ff8f18f3b7411595da32d0a28d4082",
      "ea30ed6d84124ff69487fdf991515a36",
      "46b31fcacdaf47a095a9d1651abe7df2",
      "38e416edb26a4f75868c6c2c98291537",
      "8154178d8de64d358817fe66f668be06",
      "776683caadbb467d8e4318d18ddffc9f",
      "6d67ca800945436f83cb014c184b15ab",
      "b078354b9d04427193cda12ced88da6b"
     ]
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1678827440848,
     "user": {
      "displayName": "Matt Elliott",
      "userId": "17635084586948923575"
     },
     "user_tz": 420
    },
    "id": "962df24f",
    "outputId": "749b9989-5195-494b-9b96-a02de4740161",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "guiLinearClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05680fb",
   "metadata": {
    "id": "e05680fb"
   },
   "source": [
    "Let's formalize what we've just done. For $n$ samples, define the\n",
    "petal measurements you took to be the $n$ input vectors $\\mathbf{x}_{1},\\mathbf{x}_{2},...,\\mathbf{x}_{n}$\n",
    "and the flower species to be the target output $y_{1},y_{2},...,y_{n}$, with $y_{i} = +1$ if the measurement vector $\\mathbf{x}_{i}$ comes from a tulip and $y_{i} = -1$ otherwise. In this example, there's two measurements so each vector $\\mathbf{x}_{i}\\in\\mathbb{R}^{2}$\n",
    ". For binary classifiers we'll always have $y_{i}\\in\\{-1,1\\}$. We\n",
    "can define a linear classifier as the function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46317099",
   "metadata": {
    "id": "46317099"
   },
   "source": [
    "$$\n",
    "f(\\mathbf{w},\\mathbf{x})=\\begin{cases}\n",
    "+1 & \\text{if }\\mathbf{w}\\cdot\\mathbf{x}+b>0\\\\\n",
    "-1 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cd27d7",
   "metadata": {
    "id": "76cd27d7"
   },
   "source": [
    "\n",
    "Here ${\\mathbf{w}}\\in\\mathbf{\\mathbb{R}}^{2}$ is called the weight vector and\n",
    "$b\\in\\mathbb{R}$ is called the bias. $-b$ is called the threshold. This is because $\\mathbf{w}\\cdot\\mathbf{x}+b>0$ is the same as $\\mathbf{w}\\cdot\\mathbf{x}>-b$, making $-b$ the cuttoff between $\\pm1$. To make $f(\\mathbf{w},\\mathbf{x})$\n",
    "look simpler, we can \"hide the bias\" in $\\mathbf{w}$ . Currently\n",
    "we have $\\mathbf{x}_{i}=[\\text{width},\\text{length}]$ , but instead\n",
    "let's write $\\tilde{\\mathbf{x}_{i}}=[\\text{width},\\text{length},1]$\n",
    ". For $\\tilde{\\mathbf{w}}\\cdot\\tilde{\\mathbf{x}}$ to still work we must then\n",
    "add an additional parameter to $\\tilde{\\mathbf{w}}$, so $\\tilde{\\mathbf{w}}=[w_{1},w_{2},w_{b}]\\in\\mathbf{\\mathbb{R}}^{3}$.\n",
    "If we set $w_{b}=b$ we have $\\tilde{\\mathbf{w}}\\cdot\\tilde{\\mathbf{x}}=\\mathbf{w}\\cdot\\mathbf{x}+b$\n",
    ". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a9c65c",
   "metadata": {
    "id": "a0a9c65c"
   },
   "source": [
    "\n",
    "Note that the above tulips and roses data set and its linear threshold function would now be plotted in 3 dimensions instead of 2, one dimension for each of the three components of the input vectors. This is explained in detail in the section below. Basically, since the third component is always 1, the plane containing all of the input examples illustrated in the 2-dimensional interactive widget above would actually lie one unit below the plane seen in that 2-dimensional widget.  The line that separates the roses from the tulips becomes a tilted plane through the origin that creates the separating line as it passes through the plane containing the examples. \n",
    " From now on we will always assume the threshold is written into $\\mathbf{w},\\mathbf{x}$\n",
    "and disregard the notation $\\tilde{\\mathbf{w}},\\tilde{\\mathbf{x}}$. Thus\n",
    "we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cba9370",
   "metadata": {
    "id": "2cba9370"
   },
   "source": [
    "$$\n",
    "f(\\mathbf{w},\\mathbf{x})=\\begin{cases}\n",
    "+1 & \\text{if }\\mathbf{w}\\cdot\\mathbf{x}>0\\\\\n",
    "-1 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7f5860",
   "metadata": {
    "id": "0c7f5860"
   },
   "source": [
    "## Visualizing Weights and Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04489cda",
   "metadata": {
    "id": "04489cda"
   },
   "source": [
    "So how do the weights $\\mathbf{w}$ relate to the linear classifier line that we draw? Let's go back to 2 dimensions. In the graph below, we see that $\\mathbf{w}$ defines a linear classifier through the origin that is perpendicular to it. We can see why by looking at $f(\\mathbf{w},\\mathbf{x})$ . Notice that the boundary between $\\pm1$ occures at $\\mathbf{w}\\cdot\\mathbf{x}=0$. According to the rules for [dot products](https://en.wikipedia.org/wiki/Dot_product) this means that $\\mathbf{w}$ and $\\mathbf{x}$ are perpendicular."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc65badd",
   "metadata": {
    "id": "fc65badd"
   },
   "source": [
    "To give a concrete example, in the graph below we have $\\mathbf{w}=[1,-2]$ . When we consider the equation in $f(\\mathbf{w},\\mathbf{x})$, we see that it produces the linear classifier boundary shown below.\n",
    "\n",
    "$$0=\\mathbf{w}\\cdot\\mathbf{x}=-x_{1}+2x_{2} \\iff x_{2}=\\frac{1}{2}x_{1}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bec7f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "executionInfo": {
     "elapsed": 439,
     "status": "ok",
     "timestamp": 1678827496208,
     "user": {
      "displayName": "Matt Elliott",
      "userId": "17635084586948923575"
     },
     "user_tz": 420
    },
    "id": "e8bec7f4",
    "outputId": "2d6ea7f0-7592-4cb7-d4a1-ffb695af7ea9"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "guiWeights2D()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e136335",
   "metadata": {
    "id": "3e136335"
   },
   "source": [
    "In the previous example we excluded the bias to make visualization easier to understand. How can we visualize the bias in a linear classifier? Below is an example of a dataset that is not linearly separable unless we include the bias. Notice that the line $x_2=1$ seperates the data. Looking again at the graph above, we see that the linear classifier goes through the origin. This is always true, because it's perpendicular to $\\mathbf{w}$ which always start at the origin. So then how in the world is it possible to draw a linear classifier that seperates the data below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b65091",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1678827505674,
     "user": {
      "displayName": "Matt Elliott",
      "userId": "17635084586948923575"
     },
     "user_tz": 420
    },
    "id": "f1b65091",
    "outputId": "f6aa1d73-b33b-4783-dde0-aa65daaaad71"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "guiBias2D()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac66de64",
   "metadata": {
    "id": "ac66de64"
   },
   "source": [
    "Remember that when we include the bias into the weights, $\\mathbf{x}$\n",
    "gains an additional parameter $x_{3}$ . Thus we must now consider\n",
    "a 3D graph, which is shown below. You can move the graph around using\n",
    "your mouse. $x_{3}$ is set to the same value for all inputs. Let's\n",
    "say it's always $x_{3}=1$ . This means that the points are now all\n",
    "raised up to $1$ on the $x_{3}\\text{-Axis}$ (Please verify with\n",
    "3D graph). So comparing the 3D graph to the 2D one above, the 2D graph\n",
    "is created by taking a cross section of the 3D graph at $x_{3}=1$\n",
    ". By raising all of the inputs up off of the $x_{1},x_{2}-\\text{Axis}$\n",
    "we give ourselves a little bit space that we can use to insert a linear\n",
    "classifier that goes through the origin. In this case, we have $\\mathbf{w}=[0,-1,1]$\n",
    ". Notice that if we use the equation for the classifier boundary,\n",
    "the threshold occures at $x_{2}=1$ , as seen in the 2D graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327cdac7",
   "metadata": {
    "id": "327cdac7"
   },
   "source": [
    "$$\n",
    "0=\\mathbf{w}\\cdot\\mathbf{x}=\\begin{bmatrix}0 & -1 & 1\\end{bmatrix}\\begin{bmatrix}x_{1}\\\\\n",
    "x_{2}\\\\\n",
    "1\n",
    "\\end{bmatrix}=-x_{2}+1\\iff x_{2}=1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5681bef7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "executionInfo": {
     "elapsed": 536,
     "status": "ok",
     "timestamp": 1678827510324,
     "user": {
      "displayName": "Matt Elliott",
      "userId": "17635084586948923575"
     },
     "user_tz": 420
    },
    "id": "5681bef7",
    "outputId": "8f551654-f9da-4cbb-e52f-c1a9c854fb00"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "guiBias3D()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9d0560",
   "metadata": {
    "id": "ab9d0560"
   },
   "source": [
    "## The Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab1a598",
   "metadata": {
    "id": "bab1a598"
   },
   "source": [
    "How do we determine the values of $\\mathbf{w}$ that correctly classify\n",
    "the data? We use the perceptron algorithm! The perceptron algorithm\n",
    "works like this: Randomly select some initial weights, $\\mathbf{w}_{0}$\n",
    ". Often we simply set $\\mathbf{w}_{0} = {\\bf 0}$, the all 0 vector. One by one, cycle through each\n",
    "of the input/output pairs $\\mathbf{x}_{i},y_{i}$ . If the perceptron\n",
    "correctly classifies $y_{i}$ , which means $f(\\mathbf{w},\\mathbf{x}_{i})=y_{i}$\n",
    ", then do nothing. If it misclassifies $y_{i}$ , then update the\n",
    "weights according to the rule $\\mathbf{w}_{t+1}=\\mathbf{w}_{t}+y_{i}\\mathbf{x}_{i}$\n",
    ". Notice that after $\\mathbf{w}$ changes, the value of $f(\\mathbf{w},\\mathbf{x}_{i})$\n",
    "may also change. The algorithm keeps cycling through data until everything\n",
    "is classified correctly. Because it's important, let's state the perceptorn\n",
    "update rule again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbca924e",
   "metadata": {
    "id": "bbca924e"
   },
   "source": [
    "$$\n",
    "\\mathbf{w}_{t+1}=\\begin{cases}\n",
    "\\mathbf{w}_{t}+y\\mathbf{x} & \\text{if }f(\\mathbf{w},\\mathbf{x})\\neq y\\\\\n",
    "\\mathbf{w}_{t} & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb007571",
   "metadata": {
    "id": "fb007571"
   },
   "source": [
    "Let's restate the entire algorithm again using pseudocode. Let's call\n",
    "our data, $\\mathscr{D}=\\begin{bmatrix}(\\mathbf{x}_{1},y_{1}),(\\mathbf{x}_{2},y_{2}),...,(\\mathbf{x}_{n},y_{n})\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8147efd4",
   "metadata": {
    "id": "8147efd4"
   },
   "source": [
    "**<font size=4>Perceptron$(\\mathscr{D})$**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4578f5d2",
   "metadata": {
    "id": "4578f5d2"
   },
   "source": [
    "$\\mathbf{w}= {\\bf 0}$ \n",
    "\n",
    "**WHILE:** $\\exists\\:f(\\mathbf{w},\\mathbf{x}_{i})\\neq y_{i}$ in $\\mathscr{D}$\n",
    "\n",
    "$\\quad$**FOR:** each $(\\mathbf{x}_{i},y_{i})\\in\\mathscr{D}$\n",
    "\n",
    "$\\quad$$\\quad$**IF:** $f(\\mathbf{w},\\mathbf{x}_{i})\\neq y_{i}$\n",
    "\n",
    "$\\quad$$\\quad$$\\quad$$\\mathbf{w}:=\\mathbf{w}+y\\mathbf{x}$\n",
    "\n",
    "**RETURN:** $\\mathbf{w}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e264f10",
   "metadata": {
    "id": "9e264f10"
   },
   "source": [
    "# Perceptron Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b5d8d9",
   "metadata": {
    "id": "00b5d8d9"
   },
   "source": [
    "## Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918c9b70",
   "metadata": {
    "id": "918c9b70"
   },
   "source": [
    "Let's see the perceptron in action! The interactive graph steps through every datapoint using the perceptron algorithm. Notice that by the end, the algorithm is able to correctly classify every point.\n",
    "\n",
    "\n",
    "<font color=\"gray\">Note: To make this easy to visualize, we removed the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6189942",
   "metadata": {
    "id": "f6189942",
    "outputId": "6ef58396-c193-4418-fbec-ecbfd9559eb9"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "guiPerceptron()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa2fd4e",
   "metadata": {
    "id": "faa2fd4e"
   },
   "source": [
    "## Perceptron Code "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f64193",
   "metadata": {
    "id": "05f64193"
   },
   "source": [
    "Below is a class `Perceptron` that implements the update rule for the perceptron algorithm. This code could be the starting point for a larger Perceptron class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9133884f",
   "metadata": {
    "id": "9133884f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, w ):\n",
    "        self.w = w                                               # Set initial weights when creating object\n",
    "\n",
    "    def update( self, x, y):                   \n",
    "        y_pred = -1. if np.dot(self.w, x)<0 else 1.              # Get models prediction for y        \n",
    "        self.w = self.w + (y!=y_pred) * float(y)*np.array(x)     # Update weights based on x,y,y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d14f391",
   "metadata": {
    "id": "0d14f391"
   },
   "source": [
    "Here is the data we used in the above example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e478ef53",
   "metadata": {
    "id": "e478ef53"
   },
   "outputs": [],
   "source": [
    "x=np.array([ [3.5,1.5], [-1.5,-2], [4,-1], [0,3.5], [-3.5,1], [-1.5,3], [2.5,2.5], [0.5,-4], [-3.5,-1.5], [-2.5,-2.5] ])\n",
    "y=np.array([-1,1,1,-1,-1,-1,-1,1,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58abb1f7",
   "metadata": {
    "id": "58abb1f7"
   },
   "source": [
    "Notice that as we step through the data, we get the exact same weights as shown in the visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39c1f1d",
   "metadata": {
    "id": "e39c1f1d",
    "outputId": "53bfabe1-a209-498a-cb58-64655cc20086"
   },
   "outputs": [],
   "source": [
    "learner = Perceptron([-1,-1])                  # Initial weights are w=[-1,-1]\n",
    "for i in range(len(y)):                        # Cycle through each datapoint\n",
    "    learner.update( x[i], y[i])                # Update the perceptron using x and y\n",
    "    print(f\"Step {i+1}\\tw={learner.w}\")     # Print w for each update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df34bb6",
   "metadata": {
    "id": "6df34bb6"
   },
   "source": [
    "# What is Dirac Notation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a58552c",
   "metadata": {
    "id": "7a58552c"
   },
   "source": [
    "$\\quad$In this course, as an extension of the simple classical mathematics notion for vectors and dot products used above, we will use [Dirac notation](https://en.wikipedia.org/wiki/Bra\\%E2\\%80\\%93ket\\_notation)\n",
    "(or Bra-Ket notation) created by the great physicist, Paul Dirac,\n",
    "to denote and operate on vectors. In so doing, we will also expand our treatment to include not just real numbers but also complex numbers, with a real part and an imaginary part, which is a multiple of the imaginary number $i = \\sqrt{-1}$. Complex numbers have many applications in linear algebra, not just in quantum mechanics! They are essential for understanding the central concept of eigenvalues, which we return to later.  Here we give a brief description of Bra-Ket notation. Read the\n",
    "\"mathematical interlude\" in chapter 1 of [Quantum Mechanics:\n",
    "The Theoretical Minimum](./Reading\\_Material/Quantum\\_Chapter\\_1.pdf)\n",
    "to review the necessary background material. In Bra-Ket notation, complex vectors are written in a funny\n",
    "looking way that comes in handy when you get deeper into linear algebra $|\\mathbf{a}\\rangle,|\\mathbf{b}\\rangle\\in\\mathbb{C}^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5444ae4",
   "metadata": {
    "id": "b5444ae4"
   },
   "source": [
    "$$\n",
    "\\begin{array}{ccc}\n",
    "|\\mathbf{a}\\rangle=\\begin{bmatrix}1\\\\\n",
    "i\n",
    "\\end{bmatrix} &  & |\\mathbf{b}\\rangle=\\begin{bmatrix}-1\\\\\n",
    "1+i\n",
    "\\end{bmatrix}\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885a6fe4",
   "metadata": {
    "id": "885a6fe4"
   },
   "source": [
    "In Bra-Ket notation these vectors are called Ket vectors. The Ket\n",
    "vectors have corresponding Bra vectors, $\\langle\\mathbf{a}|=\\begin{bmatrix}1,-i\\end{bmatrix}$\n",
    "and $\\langle\\mathbf{b}|=\\begin{bmatrix}-1,1-i\\end{bmatrix}$ . In\n",
    "general, a Bra is the complex conjugate transpose of some Ket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60567ac",
   "metadata": {
    "id": "d60567ac"
   },
   "source": [
    "$$\n",
    "\\langle\\mathbf{a}|=|\\mathbf{a}\\rangle^{\\dagger}=\\overline{|\\mathbf{a}\\rangle}^{T}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a62b72",
   "metadata": {
    "id": "b7a62b72"
   },
   "source": [
    "We call the conjugate transpose the \"dagger\" and symbolize it using\n",
    "$\\dagger$ . For any two vectors of complex numbers $|\\mathbf{a}\\rangle$ , $|\\mathbf{b}\\rangle$, we define their dot product (aka \"inner product\") as "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c842fb36",
   "metadata": {
    "id": "c842fb36"
   },
   "source": [
    "$$\n",
    "\\langle\\mathbf{a}|\\mathbf{b}\\rangle:=\\langle\\mathbf{a}||\\mathbf{b}\\rangle=|\\mathbf{a}\\rangle^{\\dagger}|\\mathbf{b}\\rangle\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "From now on, we'll say the word \"inner product\" instead of \"dot product\". If all the components of the vectors happen to be real numbers, then the complex conjugate doesn't change anything, and we see that\n",
    "\n",
    "$$\n",
    "\\langle\\mathbf{a}|\\mathbf{b}\\rangle = \\mathbf{a}{}^{T}\\mathbf{b}=\\mathbf{a}\\cdot\\mathbf{b}\\quad\\text{if components of }\\mathbf{a},\\mathbf{b}\\in\\mathbb{R}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eb82cb",
   "metadata": {
    "id": "c7eb82cb"
   },
   "source": [
    "This relates Bra-Ket notation to traditional dot product notation.\n",
    "A matrix $M$ can be squeezed in between a Bra and a Ket: $\\langle\\mathbf{a}|\\mathbf{M}|\\mathbf{b}\\rangle\\equiv\\mathbf{a}^{\\dagger}\\mathbf{M}\\mathbf{b}$\n",
    ". If $I$ is the identity matrix and $c$ is a complex number, then we see that $\\langle\\mathbf{a}|c\\mathbf{I}|\\mathbf{b}\\rangle=\\mathbf{a}^{\\dagger}{c}\\mathbf{b}$, so you can also squeeze a complex number in between the Bra and the Ket. \n",
    "We will define,  $\\langle\\mathbf{a}|\\mathbf{a}\\rangle:=||\\mathbf{a}||^{2}$\n",
    ". We call $\\langle\\mathbf{a}|\\mathbf{a}\\rangle$ the squared norm or squared length\n",
    "of the vector $\\mathbf{a}$. The double vertical bars are used to denote a quantity called the norm in linear algebra, and norm of a vector measures its length. (the Norm is a more general concept than length, and can apply to things other than vectors, e.g. to matrices as well). Note that the sign + or - does not matter when evaluating the squared norm, it is a \"pure magnitude\". To give a Bra-Ket example with the Perceptron,\n",
    "we can rewrite the the linear classifier $f(\\mathbf{w},\\mathbf{x})$\n",
    "as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bc5aa1",
   "metadata": {
    "id": "93bc5aa1"
   },
   "source": [
    "$$\n",
    "f(\\mathbf{w},\\mathbf{x})=\\begin{cases}\n",
    "+1 & \\text{if }\\langle\\mathbf{w}|\\mathbf{x}\\rangle>0\\\\\n",
    "-1 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb239fa",
   "metadata": {
    "id": "8bb239fa"
   },
   "source": [
    "# Perceptron Convergence Theorem "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a967e8f",
   "metadata": {
    "id": "8a967e8f"
   },
   "source": [
    "Any time a linear classifier can correclty classify all the data,\n",
    "we can show that the perceptron algorithm will find such a solution.\n",
    "Let's prove it! This proof works by considering how $\\mathbf{w}$\n",
    "changes as the number of updates to the algorithm $\\tau$ increases.\n",
    "For data that is solvable, let $\\hat{\\mathbf{w}}$ be any weight vector of length 1 that classifies the data correctly. We will put upper and lower bounds on $\\langle\\mathbf{w}|\\mathbf{w}\\rangle$\n",
    "and $\\langle\\hat{\\mathbf{w}}|\\mathbf{w}\\rangle$ in terms of $\\tau$.\n",
    "We rely on the fact that the perceptron only stops when everything\n",
    "has been classified and then use the [Cauchy-Schwarz Inequality](https://en.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality)\n",
    "has to stop at some point. This proof can be read without Bra-Ket notation in Bishop's book (chapter 3), Hertz's book (Chapter 5), and Hassoun's book (Chapter 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2bc553",
   "metadata": {
    "id": "1d2bc553"
   },
   "source": [
    "## Bound on $\\langle\\hat{\\mathbf{w}}|\\mathbf{w}\\rangle$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a21cf2",
   "metadata": {
    "id": "43a21cf2"
   },
   "source": [
    "Let start by finding a lower bound for $\\langle\\hat{\\mathbf{w}}|\\mathbf{w}\\rangle$.\n",
    "For a linear classifier to correctly classify all data, there must\n",
    "exist some weights $\\hat{\\mathbf{w}}$ for which $y_{i}=f(\\hat{\\mathbf{w}},\\mathbf{x}_{i})\\:\\forall i$\n",
    ". We start the perceptron algorithm with all zero weights $\\mathbf{w}_{0}$\n",
    ". At each step of the\n",
    "algorithm, we change $\\mathbf{w}$ using the update rule "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482ae642",
   "metadata": {
    "id": "482ae642"
   },
   "source": [
    "$$\n",
    "|\\mathbf{w}_{t+1}\\rangle=|\\mathbf{w}_{t}\\rangle+y_{i}|\\mathbf{x}_{i}\\rangle\\quad(1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c9cb6a",
   "metadata": {
    "cell_style": "center",
    "id": "91c9cb6a"
   },
   "source": [
    " where $|\\mathbf{x}_{i}\\rangle$ is a vector that is misclassified.\n",
    "After running the algorithm for a while, suppose that the number of\n",
    "times that each vector $|\\mathbf{x}_{i}\\rangle$ has been misclassified\n",
    "and updated is $\\tau_{i}\\in\\mathbb{N}$. Then the weights at this\n",
    "point are given by\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246490ad",
   "metadata": {
    "id": "246490ad"
   },
   "source": [
    "\\begin{array}{ccc}\n",
    "|\\mathbf{w}\\rangle=\\mathbf{w}_{0}+\\sum_{n}\\tau_{i}y_{i}|\\mathbf{x}_{i}\\rangle= & \\sum_{n}\\tau_{i}y_{i}|\\mathbf{x}_{i}\\rangle\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318a93a2",
   "metadata": {
    "id": "318a93a2"
   },
   "source": [
    "We now take the inner product of the above equation with $\\hat{\\mathbf{w}}$ to find our first bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd902b7",
   "metadata": {
    "id": "3dd902b7"
   },
   "source": [
    "$$\n",
    "\\begin{array}{cl}\n",
    "\\langle\\hat{\\mathbf{w}}|\\mathbf{w}\\rangle & =\\sum_{n}\\langle\\hat{\\mathbf{w}}|\\tau_{i}y_{i}|\\mathbf{x}_{i}\\rangle\\\\\n",
    " & =\\sum_{n}\\tau_{i}y_{i}\\langle\\hat{\\mathbf{w}}|\\mathbf{x}_{i}\\rangle\\\\\n",
    " & \\geq\\tau\\min_{n}y_{i}\\langle\\hat{\\mathbf{w}}|\\mathbf{x}_{i}\\rangle\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d030e33e",
   "metadata": {
    "id": "d030e33e"
   },
   "source": [
    "Where $\\tau=\\sum_{n}\\tau_{i}$ is the total number of weight updates\n",
    "and the inequality results from replacing each update vector by the\n",
    "smallest possible update. We see that $\\langle\\hat{\\mathbf{w}}|\\mathbf{w}\\rangle$\n",
    "is bounded below by a function of $\\tau$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646d71fb",
   "metadata": {
    "id": "646d71fb"
   },
   "source": [
    "## Bound on $\\langle\\mathbf{w}|\\mathbf{w}\\rangle$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286d0c02",
   "metadata": {
    "id": "286d0c02"
   },
   "source": [
    "Lets now find an upper bound for $\\langle\\mathbf{w}|\\mathbf{w}\\rangle$.\n",
    "If we take the inner product of the update rule $(1)$ we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb526ef6",
   "metadata": {
    "id": "cb526ef6"
   },
   "source": [
    "$$\n",
    "\\begin{array}{clc}\n",
    "\\langle\\mathbf{w}_{t+1}|\\mathbf{w}_{t+1}\\rangle & =\\langle\\mathbf{w}_{t}|\\mathbf{w}_{t}\\rangle+\\langle\\mathbf{x}_{i}|y_{i}^{2}|\\mathbf{x}_{i}\\rangle+2y_{i}\\langle\\mathbf{w}_{t}|\\mathbf{x}_{i}\\rangle\\\\\n",
    " & \\leq\\langle\\mathbf{w}_{t}|\\mathbf{w}_{t}\\rangle+\\langle\\mathbf{x}_{i}|y_{i}^{2}|\\mathbf{x}_{i}\\rangle\\\\\n",
    " & =\\langle\\mathbf{w}_{t}|\\mathbf{w}_{t}\\rangle+\\langle\\mathbf{x}_{i}|\\mathbf{x}_{i}\\rangle & \\leftarrow\\text{since }y_{i}^{2}=1\\\\\n",
    " & \\leq\\langle\\mathbf{w}_{t}|\\mathbf{w}_{t}\\rangle+\\langle\\mathbf{x}|\\mathbf{x}\\rangle_{\\max}\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c7bf4",
   "metadata": {
    "id": "4d3c7bf4"
   },
   "source": [
    "where the first inequality follows from the fact that $|\\mathbf{x}_{i}\\rangle$\n",
    "was missclassified, look inside the equation $f(\\hat{\\mathbf{w}},\\mathbf{x})$\n",
    "to notice that this means $y_{i}\\langle\\mathbf{w}_{t}|\\mathbf{x}_{i}\\rangle<0$\n",
    ". We also define $\\langle\\mathbf{x}|\\mathbf{x}\\rangle_{\\max}$ as\n",
    "the inner product of the largest input so that $\\langle\\mathbf{x}_{i}|\\mathbf{x}_{i}\\rangle\\leq\\langle\\mathbf{x}|\\mathbf{x}\\rangle_{\\max}$\n",
    ". If we now consider the change $\\Delta$ in the value of $\\langle\\mathbf{w}|\\mathbf{w}\\rangle$\n",
    "we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244d3ef2",
   "metadata": {
    "id": "244d3ef2"
   },
   "source": [
    "$$\n",
    "\\Delta\\langle\\mathbf{w}|\\mathbf{w}\\rangle\\equiv\\langle\\mathbf{w}_{t+1}|\\mathbf{w}_{t+1}\\rangle-\\langle\\mathbf{w}_{t}|\\mathbf{w}_{t}\\rangle\\leq\\langle\\mathbf{x}|\\mathbf{x}\\rangle_{\\max}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a5f266",
   "metadata": {
    "id": "c4a5f266"
   },
   "source": [
    "and so after $\\tau$ updates we have the following upper bound on\n",
    "$\\langle\\mathbf{w}|\\mathbf{w}\\rangle$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63ad291",
   "metadata": {
    "id": "d63ad291"
   },
   "source": [
    "$$\n",
    "\\langle\\mathbf{w}|\\mathbf{w}\\rangle\\leq\\tau\\langle\\mathbf{x}|\\mathbf{x}\\rangle_{\\max}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f03ce",
   "metadata": {
    "id": "394f03ce"
   },
   "source": [
    "## Cauchy-Schwarz Inequality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e6bd27",
   "metadata": {
    "id": "e6e6bd27"
   },
   "source": [
    "The [Cauchy-Schwarz inequality](https://en.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality) is one of the most important inequalities in math. It states that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d1296c",
   "metadata": {
    "id": "36d1296c"
   },
   "source": [
    "$$\n",
    "\\dfrac{|\\langle\\hat{\\mathbf{w}}|\\mathbf{w}\\rangle|^{2}}{\\langle\\mathbf{w}|\\mathbf{w}\\rangle\\langle\\hat{\\mathbf{w}}|\\hat{\\mathbf{w}}\\rangle}\\leq1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eacb57e",
   "metadata": {
    "id": "7eacb57e"
   },
   "source": [
    "We now show that this inequality puts an upper limit on the number\n",
    "of updates $\\tau$. We just saw that $\\langle\\hat{\\mathbf{w}}|\\mathbf{w}\\rangle$\n",
    "and $\\langle\\mathbf{w}|\\mathbf{w}\\rangle$ have bounds that grow in\n",
    "terms $\\tau$. By plugging in the smallest posssible value of $\\langle\\hat{\\mathbf{w}}|\\mathbf{w}\\rangle$\n",
    "into the numerator and the largest possible value of $\\langle\\mathbf{w}|\\mathbf{w}\\rangle$\n",
    "into the denominator of the left side of the equation, we maximize\n",
    "the number of possible updates that can occur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7d31d5",
   "metadata": {
    "id": "2c7d31d5"
   },
   "source": [
    "$$\n",
    "\\begin{array}{cl}\n",
    " & \\dfrac{\\begin{pmatrix}\\tau\\min_{n}y_{i}\\langle\\hat{\\mathbf{w}}|\\mathbf{x}_{i}\\rangle\\end{pmatrix}^{2}}{\\tau\\langle\\mathbf{x}|\\mathbf{x}\\rangle_{\\max}\\langle\\hat{\\mathbf{w}}|\\hat{\\mathbf{w}}\\rangle}=\\dfrac{\\tau^{2}\\begin{pmatrix}\\min_{n}y_{i}\\langle\\hat{\\mathbf{w}}|\\mathbf{x}_{i}\\rangle\\end{pmatrix}^{2}}{\\tau\\langle\\mathbf{x}|\\mathbf{x}\\rangle_{\\max}\\langle\\hat{\\mathbf{w}}|\\hat{\\mathbf{w}}\\rangle}=\\tau\\dfrac{\\begin{pmatrix}\\min_{n}y_{i}\\langle\\hat{\\mathbf{w}}|\\mathbf{x}_{i}\\rangle\\end{pmatrix}^{2}}{\\langle\\mathbf{x}|\\mathbf{x}\\rangle_{\\max}\\langle\\hat{\\mathbf{w}}|\\hat{\\mathbf{w}}\\rangle}\\leq1\\\\\n",
    "\\\\\n",
    "\\iff & \\tau\\leq\\dfrac{\\langle\\mathbf{x}|\\mathbf{x}\\rangle_{\\max}\\langle\\hat{\\mathbf{w}}|\\hat{\\mathbf{w}}\\rangle}{\\begin{pmatrix}\\min_{n}y_{i}\\langle\\hat{\\mathbf{w}}|\\mathbf{x}_{i}\\rangle\\end{pmatrix}^{2}}\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c562d223",
   "metadata": {
    "id": "c562d223"
   },
   "source": [
    "The very last inqueality shows that $\\tau$ must be less than or equal\n",
    "to the equation on the right. If there were any more updates\n",
    "than that we'd break the Cauchy-Schwartz Inequality. Notice that this right\n",
    "hand equation is written purely in terms of $\\hat{\\mathbf{w}},\\mathbf{x}_{i},y_{i}\\:\\forall i$\n",
    ", which are values that were given to us at the very beginning of\n",
    "the proof, before the perceptron algorithm was started. Thus\n",
    "we could calculate the maximum possible number of perceptron updates\n",
    "before we ever run the algorithm. We have proven the perceptron convergence\n",
    "theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68f990d",
   "metadata": {
    "id": "d68f990d"
   },
   "source": [
    "## Understanding Max Updates "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e9bc63",
   "metadata": {
    "id": "21e9bc63"
   },
   "source": [
    "Previously we showed that the maximum number of possible updates $\\tau$\n",
    "for the perceptron algorithm is bounded above by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0604d88d",
   "metadata": {
    "id": "0604d88d"
   },
   "source": [
    "$$\n",
    "\\tau\\leq\\dfrac{\\langle\\mathbf{x}|\\mathbf{x}\\rangle_{\\max}\\langle\\hat{\\mathbf{w}}|\\hat{\\mathbf{w}}\\rangle}{\\begin{pmatrix}\\min_{n}y_{i}\\langle\\hat{\\mathbf{w}}|\\mathbf{x}_{i}\\rangle\\end{pmatrix}^{2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdddeddd",
   "metadata": {
    "id": "cdddeddd"
   },
   "source": [
    "The right hand equation looks messy, but with a little thinking\n",
    "we can actually make sense of it. For starters, we are going to simplify\n",
    "the problem by normalizing $\\hat{\\mathbf{w}},\\mathbf{x}_{i}\\,\\forall i$\n",
    ". This means that we're now choosing an \"all correct\" weights\n",
    "vector $\\hat{\\mathbf{w}}$ such that $\\langle\\hat{\\mathbf{w}}|\\hat{\\mathbf{w}}\\rangle=1$\n",
    ", and we are rescaling every input $\\mathbf{x}_{i}$ so that $\\langle\\mathbf{x}_{i}|\\mathbf{x}_{i}\\rangle=1$\n",
    ". Are we allowed to do this? Yes. Remember that our goal is to find\n",
    "a line (linear classifier) that correctly splits the data in two.\n",
    "Notice in the graph below, that the correctness of this linear\n",
    "classifier only depends on the angle of the data points and the weights vector,\n",
    "not on their magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bd176b",
   "metadata": {
    "id": "d3bd176b",
    "outputId": "88df9fed-cb42-4a25-9bb0-14f150111028"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "guiNormalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011346f7",
   "metadata": {
    "id": "011346f7"
   },
   "source": [
    "With our normalized data and weights, the right hand equation becomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba41bf64",
   "metadata": {
    "id": "ba41bf64"
   },
   "source": [
    "$$\n",
    "\\dfrac{\\langle\\mathbf{x}|\\mathbf{x}\\rangle_{\\max}\\langle\\hat{\\mathbf{w}}|\\hat{\\mathbf{w}}\\rangle}{\\begin{pmatrix}\\min_{i}y_{i}\\langle\\hat{\\mathbf{w}}|\\mathbf{x}_{i}\\rangle\\end{pmatrix}^{2}}=\\dfrac{(1)(1)}{\\begin{pmatrix}\\min_{i}y_{i}\\langle\\hat{\\mathbf{w}}|\\mathbf{x}_{i}\\rangle\\end{pmatrix}^{2}}=\\dfrac{1}{\\begin{pmatrix}\\min_{i}|\\langle\\hat{\\mathbf{w}}|\\mathbf{x}_{i}\\rangle|\\end{pmatrix}^{2}}\\:\\leftarrow y_{i}\\langle\\hat{\\mathbf{w}}|\\mathbf{x}_{i}\\rangle>0\\text{ and }y_{i}=\\pm1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dc9ec1",
   "metadata": {
    "id": "f3dc9ec1"
   },
   "source": [
    "Remember that the dot product tells us that the angle between two vectors is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9001c5",
   "metadata": {
    "id": "5e9001c5"
   },
   "source": [
    "$$\n",
    "\\cos\\theta=\\frac{\\langle\\hat{\\mathbf{w}}|\\mathbf{x}_{i}\\rangle}{||\\mathbf{x}_{i}||\\:||\\hat{\\mathbf{w}}||}=\\langle\\hat{\\mathbf{w}}|\\mathbf{x}_{i}\\rangle\\:\\leftarrow||\\mathbf{x}_{i}||=||\\hat{\\mathbf{w}}||=1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf017904",
   "metadata": {
    "id": "bf017904"
   },
   "source": [
    "Plugging the angles for our input data into the equation for $\\tau$ yields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cf2236",
   "metadata": {
    "id": "08cf2236"
   },
   "source": [
    "$$\n",
    "\\tau\\leq\\dfrac{1}{\\min_{i}|\\langle\\hat{\\mathbf{w}}|\\mathbf{x}_{i}\\rangle|^{2}}=\\dfrac{1}{\\min_{i}|\\cos\\theta_{i}|^{2}}=\\max_{i}|\\cos\\theta_{i}|^{-2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2f54eb",
   "metadata": {
    "id": "8d2f54eb"
   },
   "source": [
    "Review the [unit circle](https://en.wikipedia.org/wiki/Unit_circle) for cosine. Notice that the angle\n",
    "$\\theta_{i}$ between $\\mathbf{x}_{i}$ and $\\mathbf{\\hat{w}}$\n",
    "maximizes $|\\cos\\theta_{i}|^{-2}=\\infty$ when they are perpendicular $(\\theta=\\pm\\pi)$.\n",
    "The angle $\\theta_{i}$ minimizes $|\\cos\\theta_{i}|^{-2}=1$ when\n",
    "they are parallel $(\\theta=0)$. Remember that the linear classifier boundary is\n",
    " always perpendicular to $\\hat{\\mathbf{w}}$ , which is also the same place where $|\\cos\\theta_{i}|^{-2}$ is maximized. What this means\n",
    "is that the maximum number of updates is determined by the \"hardest\n",
    "to classify\" data point that lies closest to the decision boundary.\n",
    "The closer this data point is to the boundary the longer the perceptron algorthim\n",
    "may take to run. Intuitively this makes a lot of sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6eed0e9",
   "metadata": {
    "id": "d6eed0e9"
   },
   "source": [
    "# <font color=\"red\">Exercises 23/23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cfa2ce",
   "metadata": {
    "id": "47cfa2ce"
   },
   "source": [
    "In this lecture we considered how one might go about building an algorithm that is able to correctly distinguish between two items based on data about them. For example, how to classify tulips from roses, when give measurments from the flowers. We showed that a linear classifier can be used to \"draw a line\" between the datapoints in order to classify them into one of two categories. We then introduced the perceptron algorithm as a method for finding an appropriate linear classifier given some data. Below are exercises to further familiarize yourself with this material."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd900a75",
   "metadata": {},
   "source": [
    "Suggest wolfram alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8167741",
   "metadata": {},
   "source": [
    "## Dirac Notation  <font color=\"red\"> 7.5/8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a66bb9",
   "metadata": {},
   "source": [
    "### Simple Calculations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f23d1f3",
   "metadata": {},
   "source": [
    "Consider the following Matrices, Vectors and Scalar:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fb7f21",
   "metadata": {},
   "source": [
    "$$\n",
    "|\\mathbf{a}\\rangle=\\begin{bmatrix}\\begin{array}{c}\n",
    "2\\\\\n",
    "-i\\\\\n",
    "3+i\n",
    "\\end{array}\\end{bmatrix}\\qquad|\\mathbf{b}\\rangle=\\begin{bmatrix}\\begin{array}{c}\n",
    "\\pi\\\\\n",
    "53\\\\\n",
    "2-i\n",
    "\\end{array}\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8deebbe",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{M}=\\begin{bmatrix}\\begin{array}{ccc}\n",
    "4 & 2 & 1\\\\\n",
    "5 & 5 & 2\\\\\n",
    "1 & 1 & 3\n",
    "\\end{array}\\end{bmatrix}\\qquad c=4\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d911f6ed",
   "metadata": {},
   "source": [
    "Calculate the following: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884cf3d5",
   "metadata": {},
   "source": [
    "<b><font color=\"green\">Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01372c29",
   "metadata": {},
   "source": [
    "$\\langle\\mathbf{a}|\\mathbf{b}\\rangle = 2\\pi+5+48i $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7630f1aa",
   "metadata": {},
   "source": [
    "<font color=\"red\"> 1/1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a503629d",
   "metadata": {},
   "source": [
    "$\\langle\\mathbf{a}|\\mathbf{M}|\\mathbf{b}\\rangle = 11\\pi + 392 + i(199+4\\pi)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c020caf2",
   "metadata": {},
   "source": [
    "<font color=\"red\"> 1/1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4618e60",
   "metadata": {},
   "source": [
    "$|\\mathbf{a}\\rangle\\langle\\mathbf{b}| = \\begin{bmatrix}\\begin{array}{ccc}\n",
    "2\\pi & 106 & 4+2i\\\\\n",
    "-\\pi i & -53i & 1-2i\\\\\n",
    "3\\pi + \\pi i & 159+53i & 5+5i\n",
    "\\end{array}\\end{bmatrix}\\qquad\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6d904f",
   "metadata": {},
   "source": [
    "<font color=\"red\"> 1/1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0579f54",
   "metadata": {},
   "source": [
    "$c\\mathbf{M}\\begin{pmatrix}|\\mathbf{a}\\rangle+|\\mathbf{b}\\rangle\\end{pmatrix} = \\begin{bmatrix}\\begin{array}{ccc}\n",
    "16\\pi + 476 -8i\\\\\n",
    "20\\pi + 1140 -20i\\\\\n",
    "4\\pi + 280 -4i\n",
    "\\end{array}\\end{bmatrix}\\qquad\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6e5dfa",
   "metadata": {},
   "source": [
    "<font color=\"red\"> 1/1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a60c35",
   "metadata": {},
   "source": [
    "$c\\mathbf{M}|\\mathbf{a}\\rangle+c\\mathbf{M}|\\mathbf{b}\\rangle = \\begin{bmatrix}\\begin{array}{ccc}\n",
    "16\\pi + 476 -8i\\\\\n",
    "20\\pi + 1140 -20i\\\\\n",
    "4\\pi + 280 -4i\n",
    "\\end{array}\\end{bmatrix}\\qquad\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0280ae6e",
   "metadata": {},
   "source": [
    "<font color=\"red\"> 1/1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62973a1b",
   "metadata": {},
   "source": [
    "### Convergence Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439b1035",
   "metadata": {},
   "source": [
    "Rewrite the section of the proof of the Perceptron Convergence Theorem that puts a bound on $\\langle\\hat{\\mathbf{w}}|\\mathbf{w}\\rangle$ (section 5.1), however, this time use dot products instead of Dirac notation. I reccomend doing this proof in `Latex`. Alternatively, you can write it by hand, take a photo, upload the photo to the Perceptron folder, and then insert the photo into a markdown cell with a command, something like `![](My_Photo.png)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952b9982",
   "metadata": {},
   "source": [
    "<b><font color=\"green\">Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e8b8bf",
   "metadata": {},
   "source": [
    "Let start by finding a lower bound for  $ùê∞ÃÇ^{\\dagger}ùê∞$\n",
    " . For a linear classifier to correctly classify all data, there must exist some weights  ùê∞ÃÇ \n",
    "  for which  ùë¶ùëñ=ùëì(ùê∞ÃÇ ,ùê±ùëñ)‚àÄùëñ\n",
    "  . We start the perceptron algorithm with all zero weights  ùê∞0\n",
    "  . At each step of the algorithm, we change  ùê∞\n",
    "  using the update rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289910c0",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{w}_{t+1}=\\mathbf{w}_{t}+y_{i}\\mathbf{x}_{i}\\quad(1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c81ba7",
   "metadata": {},
   "source": [
    " where $\\mathbf{x}_{i}$ is a vector that is misclassified.\n",
    "After running the algorithm for a while, suppose that the number of\n",
    "times that each vector $\\mathbf{x}_{i}$ has been misclassified\n",
    "and updated is $\\tau_{i}\\in\\mathbb{N}$. Then the weights at this\n",
    "point are given by\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d3efb3",
   "metadata": {},
   "source": [
    "\\begin{array}{ccc}\n",
    "\\mathbf{w}=\\mathbf{w}_{0}+\\sum_{n}\\tau_{i}y_{i}\\mathbf{x}_{i}= & \\sum_{n}\\tau_{i}y_{i}\\mathbf{x}_{i}\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac6cc2f",
   "metadata": {},
   "source": [
    "We now take the inner product of the above equation with $\\hat{\\mathbf{w}}$ to find our first bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bcd29a",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{cl}\n",
    " ùê∞ÃÇ^{\\dagger}ùê∞ & =\\sum_{n}\\hat{\\mathbf{w}}^{\\dagger}\\cdot\\tau_{i}y_{i}\\cdot\\mathbf{x}_{i}\\\\\n",
    " & =\\sum_{n}\\tau_{i}y_{i}\\cdot\\hat{\\mathbf{w}}^{\\dagger}\\cdot\\mathbf{x}_{i}\\\\\n",
    " & \\geq\\tau\\min_{n}y_{i}\\cdot\\hat{\\mathbf{w}}^{\\dagger}\\cdot\\mathbf{x}_{i}\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed61e8c",
   "metadata": {},
   "source": [
    "Where $\\tau=\\sum_{n}\\tau_{i}$ is the total number of weight updates\n",
    "and the inequality results from replacing each update vector by the\n",
    "smallest possible update. We see that $\\langle\\hat{\\mathbf{w}}|\\mathbf{w}\\rangle$\n",
    "is bounded below by a function of $\\tau$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4559e173",
   "metadata": {},
   "source": [
    "<font color=\"red\"> 2.5/3 +0.5 for taking into account complex numbers, -1 for doing the dot product with scalars $(\\tau_{i}y_{i}\\cdot\\mathbf{x}_{i})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca27fad",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Linear Separability <font color=\"red\"> 7/7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3556a9",
   "metadata": {
    "hidden": true,
    "id": "ca3556a9"
   },
   "source": [
    "Below are some exercises to familiarize yourself with the perceptron algorithm. Before you start the exercises, please first read over the source code that was used to make the graphics in this notebook. The following exercises are considerably easier if you copy/paste the source code and the edit it. For the following exercises, consider the dataset below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206909bc",
   "metadata": {
    "hidden": true,
    "id": "206909bc"
   },
   "outputs": [],
   "source": [
    "x = np.array([[-.7,.2],[.5,.5],[.7,.3],[-.3,.6],[0,.7],[-.5,-.5],[.8,-.2],[.1,-.8],[-.7,-.3],[-.3,-.4]])  \n",
    "y = np.array([-1,-1,-1,-1,-1,1,1,1,1,-1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527f88c4",
   "metadata": {
    "hidden": true,
    "id": "527f88c4"
   },
   "source": [
    "### Graph New Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6d4a57",
   "metadata": {
    "hidden": true,
    "id": "9a6d4a57"
   },
   "source": [
    "Graph this dataset. The simplest way to do this is to change one of the functions from the source code. Choose whichever code block works best for you. Don't edit the code directly in the source code file, instead, copy it below and then make changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2345a32",
   "metadata": {
    "hidden": true,
    "id": "d2345a32"
   },
   "source": [
    "<b><font color=\"green\">Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d35da7d",
   "metadata": {
    "hidden": true,
    "id": "9d35da7d"
   },
   "outputs": [],
   "source": [
    "#new data\n",
    "x = np.array([[-.7,.2],[.5,.5],[.7,.3],[-.3,.6],[0,.7],[-.5,-.5],[.8,-.2],[.1,-.8],[-.7,-.3],[-.3,-.4]])  \n",
    "y = np.array([-1,-1,-1,-1,-1,1,1,1,1,-1]) \n",
    "\n",
    "plt.rcParams[\"figure.figsize\"]=7,7              # Set size of plot\n",
    "    \n",
    "# Creat sublot framework\n",
    "#fig, (plt1, plt2) = plt.subplots(1, 2)\n",
    "    \n",
    "# Create First Plot Draw Scatter of initial Data\n",
    "plt.axhline(0, color=\"gray\", linewidth=.5)\n",
    "plt.axvline(0, color='gray', linewidth=.5)\n",
    "colormap = np.array(['dummy', 'orange', 'blue'])\n",
    "plt.scatter( x[:,0], x[:,1], c=colormap[y]) #c=colormap[y])#, cmap=colormap[y])         # Create scatter plot of data\n",
    "plt.legend( [Patch(\"b\",\"b\"),Patch(\"orange\",\"orange\")], [\"$-1$\",\"$1$\"], loc=\"lower right\")       # Add legend\n",
    "#plt.set_title(\"Unnormalized\")\n",
    "#plt.axis([-2, 2, -2, 2]) \n",
    "#plt.axis([-1, 1, -1, 1])    \n",
    "    \n",
    "# Draw data initial weights for  w=[ 0.5 -4.5]\n",
    "#w=np.array([ 0.5, -4.5])/3\n",
    "#plt1.arrow(0, 0, w[0], w[1], facecolor=\"g\",alpha=.5, width = 0.02, length_includes_head=True, edgecolor=\"None\") \n",
    "#plt1.plot( [-10,10], -w[0]/w[1] * np.array([-10,10]), c=\"black\", linewidth=1)    # Linear classifier line\n",
    "    \n",
    "# Normalize data and draw scatter\n",
    "x_norm = sklearn.preprocessing.normalize(x)\n",
    "#w_norm = sklearn.preprocessing.normalize(w.reshape(1, -1))[0]\n",
    "#for i in x_norm:\n",
    "#   plt.arrow(0, 0, i[0], i[1], facecolor=\"yellow\",alpha=.5, width = 0.02, length_includes_head=True, edgecolor=\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc4d1a0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font color=\"red\"> 1/1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbede8d",
   "metadata": {
    "hidden": true,
    "id": "adbede8d"
   },
   "source": [
    "###  Describe Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8018252c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How does this dataset compare to the example we used earlier? Is it linearly separable? Explain. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c09d19",
   "metadata": {
    "hidden": true,
    "id": "06c09d19"
   },
   "source": [
    "<b><font color=\"green\">Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eea866",
   "metadata": {
    "hidden": true,
    "id": "d7eea866"
   },
   "source": [
    "No, because there is no way to draw one linear straight line that seperates the yellow dots (1) and the blue dots (-1). That blue dot on the bottom half prevents us from doing so, because no matter how we draw the line there is no way for one side to have all yellow allthe other all blue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1787f3df",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font color=\"red\"> 2/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73f55fc",
   "metadata": {
    "hidden": true,
    "id": "f73f55fc"
   },
   "source": [
    "### Predict Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faf87e6",
   "metadata": {
    "hidden": true,
    "id": "0faf87e6"
   },
   "source": [
    "What do you think will happen if you run the perceptron algorithm on thise dataset? Will it converge?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5080063f",
   "metadata": {
    "hidden": true,
    "id": "5080063f"
   },
   "source": [
    "<b><font color=\"green\">Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525767e0",
   "metadata": {
    "hidden": true,
    "id": "525767e0"
   },
   "source": [
    "No. Because its not linearly seperable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac2a67d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font color=\"red\"> 2/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a205bad1",
   "metadata": {
    "hidden": true,
    "id": "a205bad1"
   },
   "source": [
    "### Run Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165703dd",
   "metadata": {
    "hidden": true,
    "id": "165703dd"
   },
   "source": [
    "Copy the code from `guiPerceptron` to below. Edit it so that it uses the new dataset and so that you see the first 1000 steps of the perceptron algorithm. **Hint:** To complete this exercise, you only need to add 3 additional characters to the code. Plot the results from theses changes below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb320f6",
   "metadata": {
    "hidden": true,
    "id": "3bb320f6"
   },
   "source": [
    "<b><font color=\"green\">Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412e6be6",
   "metadata": {
    "hidden": true,
    "id": "412e6be6"
   },
   "outputs": [],
   "source": [
    "def guiPerceptron(x,y):\n",
    "    # old Dataset\n",
    "    #x = np.array([[-.7,.2],[.5,.5],[.7,.3],[-.3,.6],[0,.7],[-.5,-.5],[.8,-.2],[.1,-.8],[-.7,-.3],[-.3,-.4]])  \n",
    "    #y = np.array([-1,-1,-1,-1,-1,1,1,1,1,1])     #y = np.array([1,1,1,1,1,-1,-1,-1,-1,-1]) # alternate example\n",
    "\n",
    "    #new data\n",
    "    x = np.array([[-.7,.2],[.5,.5],[.7,.3],[-.3,.6],[0,.7],[-.5,-.5],[.8,-.2],[.1,-.8],[-.7,-.3],[-.3,-.4]])  \n",
    "    y = np.array([-1,-1,-1,-1,-1,1,1,1,1,-1]) \n",
    "\n",
    "    np.random.seed(1)\n",
    "    ites= np.random.choice(10,10,replace=False)\n",
    "    x,y = x[ites]*5, y[ites]\n",
    "\n",
    "    @interact( step=(0, 1000, 1) )  # Creates an interactive GUI\n",
    "    def f(step):  \n",
    "        # Scatterplot of datapoints\n",
    "        plt.rcParams[\"figure.figsize\"]=8,8              # Set size of plot\n",
    "        plt.axhline(0, color=\"gray\", linewidth=.5)\n",
    "        plt.axvline(0, color='gray', linewidth=.5)\n",
    "        colormap = np.array(['dummy', 'orange', 'blue'])\n",
    "        plt.scatter( x[:,0], x[:,1], c=colormap[y]) #c=colormap[y])#, cmap=colormap[y])         # Create scatter plot of data\n",
    "        plt.legend( [Patch(\"b\",\"b\"),Patch(\"orange\",\"orange\")], [\"$-1$\",\"$1$\"], loc=\"lower right\")       # Add legend\n",
    "        plt.axis([-5, 5, -5, 5])                             # Set x and y axis\n",
    "\n",
    "        # set up perceptron  and step through updates\n",
    "        w = [-1,-1]\n",
    "        learner= PerceptronSimple(w)\n",
    "        for j in range(step):\n",
    "            i = j % len(y)                  # Cycle through datapoints over and over again\n",
    "            learner.update(x[i],y[i])       # Draw weights vector and correpsonding Linear Classifier\n",
    "\n",
    "        # Show the last point that was updated\n",
    "        if step==0:\n",
    "            display(ipw.HTMLMath(\"<h4>The <span class='text-success'>weight vector</span> is initialized to $w=[-1,-1]$</h4>\") )\n",
    "        elif step>0 and y[i]==learner.data.y_pred[i]:\n",
    "            display(ipw.HTMLMath(f\"<h4>The selected point $x=[{x[i,0]},{x[i,1]}]$ was <span class='text-success'>correctly classified</span>. No update occurs.</h4>\") )\n",
    "            plt.scatter( x[i,0], x[i,1], s=300 , facecolors=\"none\", edgecolors=\"g\", linewidth=2 )\n",
    "        elif step>0 and y[i]>learner.data.y_pred[i]:\n",
    "            display(ipw.HTMLMath(f\"<h4>The selected point $x=[{x[i,0]},{x[i,1]}]$ was <span class='text-danger'>incorrecttly classified</span>. Since $y=$<font color='orange'>$1$</font>, we have \"+\"$w_t=w_{t-1}+x$</h4>\") )\n",
    "            plt.scatter( x[i,0], x[i,1], s=300 , facecolors=\"none\", edgecolors=\"r\", linewidth=2 )\n",
    "            plt.arrow( 0,0, x[i,0],x[i,1], facecolor=\"r\",alpha=.5, width = 0.05, length_includes_head=True, edgecolor=\"None\")\n",
    "            plt.arrow(0, 0, learner.data.w[-1,0],learner.data.w[-1,1], facecolor=\"g\",alpha=.5, width = 0.05, length_includes_head=True, edgecolor=\"None\")  \n",
    "            plt.arrow( learner.data.w[-1,0],learner.data.w[-1,1], x[i,0],x[i,1], facecolor=\"r\",alpha=.5, width = 0.05, length_includes_head=True, edgecolor=\"None\")  \n",
    "        elif step>0 and y[i]<learner.data.y_pred[i]:\n",
    "            display(ipw.HTMLMath(f\"<h4>The selected point $x=[{x[i,0]},{x[i,1]}]$ was <span class='text-danger'>incorrecttly classified</span>. Since $y=$<font color='blue'>$-1$</font>, we have \"+\"$w_t=w_{t-1}-x$</h4>\") )\n",
    "            plt.scatter( x[i,0], x[i,1], s=300 , facecolors=\"none\", edgecolors=\"r\", linewidth=2 )\n",
    "            plt.arrow( 0,0, x[i,0],x[i,1], facecolor=\"r\",alpha=.5, width = 0.05, length_includes_head=True, edgecolor=\"None\")\n",
    "            plt.arrow(0, 0, learner.data.w[-1,0],learner.data.w[-1,1], facecolor=\"g\",alpha=.5, width = 0.05, length_includes_head=True, edgecolor=\"None\")  \n",
    "            plt.arrow( learner.data.w[-1,0],learner.data.w[-1,1], -x[i,0],-x[i,1], facecolor=\"r\",alpha=.5, width = 0.05, length_includes_head=True, edgecolor=\"None\")     \n",
    "\n",
    "        # check which are classified positive\n",
    "        for j in range(len(x)):\n",
    "            if learner.predict(x[j]) != y[j]:\n",
    "                plt.scatter( x[j,0], x[j,1],  s=220 ,facecolors=\"none\", edgecolors=\"r\", linewidth=.3 ) \n",
    "        plt.arrow(0,0, learner.w[0],learner.w[1], facecolor=\"green\", width=0.1, length_includes_head=True, edgecolor=\"None\") \n",
    "        plt.plot( [-10,10], -learner.w[0]/learner.w[1] * np.array([-10,10]), c=\"black\", linewidth=1)    # Linear classifier line\n",
    "guiPerceptron(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446940f3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font color=\"red\"> 1/1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e14534",
   "metadata": {
    "hidden": true,
    "id": "e7e14534"
   },
   "source": [
    "### Analyze Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ea9e17",
   "metadata": {
    "hidden": true,
    "id": "64ea9e17"
   },
   "source": [
    "Look what happens as you cycle through the algorithm at different points of the 1000 steps. Does the algorithm converge according to the **Perceptron Convergence Theorem**? Explain the reasoning for your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6a8500",
   "metadata": {
    "hidden": true,
    "id": "2c6a8500"
   },
   "source": [
    "<b><font color=\"green\">Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c7675e",
   "metadata": {
    "hidden": true,
    "id": "c9c7675e"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d72c4444",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The Perceptron Convergence Theorem only applies if linear classifier can correctly classify the data, in this case it can't. Therefore, the fact it does not converge does not conflict with the Perceptron Convergance Theorem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d18df",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font color=\"red\"> 1/1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3fb537",
   "metadata": {},
   "source": [
    "## Small Margin <font color=\"red\"> 8.5/8\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026a4885",
   "metadata": {},
   "source": [
    "Consider the two datasets below. The weight vector $\\hat{\\mathbf{w}}=[0,1]$ produces the optimal linear classifier for both datasets.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853477ea",
   "metadata": {},
   "source": [
    "Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c09d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= np.array([[ 0.93969262,0.34202014],[0.76604444,  0.64278761],[0.5,0.8660254 ],[0.17364818,0.98480775],[-0.17364818,  0.98480775],[-0.5,  0.8660254 ],[-0.76604444,  0.64278761],[-0.93969262,  0.34202014],[-0.93969262, -0.34202014],[-0.76604444, -0.64278761],[-0.5, -0.8660254 ],[-0.17364818, -0.98480775],[ 0.17364818, -0.98480775],[ 0.5, -0.8660254 ],[ 0.76604444, -0.64278761],[ 0.93969262, -0.34202014]])\n",
    "y= np.array([-1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda968c8",
   "metadata": {},
   "source": [
    "Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575caccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array( [[0.76604444, 0.64278761],[ 0.5,0.8660254],[0.17364818,0.98480775],[-0.17364818, 0.98480775],[-0.5, 0.8660254],[-0.76604444, 0.64278761],[-0.76604444, -0.64278761],[-0.5, -0.8660254 ],[-0.17364818, -0.98480775],[ 0.17364818, -0.98480775],[0.5,-0.8660254],[0.76604444,-0.64278761]] )\n",
    "y = np.array([-1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363ecc8b",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c962aa",
   "metadata": {},
   "source": [
    "Make a plot of both datasets. In each plot include the datapoints, the weight vector, and the decision boudnary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85034442",
   "metadata": {},
   "source": [
    "<b><font color=\"green\">Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2342d2",
   "metadata": {},
   "source": [
    "**Dataset 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc47276",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= np.array([[ 0.93969262,0.34202014],[0.76604444,  0.64278761],[0.5,0.8660254 ],[0.17364818,0.98480775],[-0.17364818,  0.98480775],[-0.5,  0.8660254 ],[-0.76604444,  0.64278761],[-0.93969262,  0.34202014],[-0.93969262, -0.34202014],[-0.76604444, -0.64278761],[-0.5, -0.8660254 ],[-0.17364818, -0.98480775],[ 0.17364818, -0.98480775],[ 0.5, -0.8660254 ],[ 0.76604444, -0.64278761],[ 0.93969262, -0.34202014]])\n",
    "y= np.array([-1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"]=7,7              # Set size of plot\n",
    "    \n",
    "# Creat sublot framework\n",
    "#fig, (plt1, plt2) = plt.subplots(1, 2)\n",
    "    \n",
    "# Create First Plot Draw Scatter of initial Data\n",
    "plt.axhline(0, color=\"gray\", linewidth=.5)\n",
    "plt.axvline(0, color='gray', linewidth=.5)\n",
    "colormap = np.array(['dummy', 'orange', 'blue'])\n",
    "plt.scatter( x[:,0], x[:,1], c=colormap[y]) #c=colormap[y])#, cmap=colormap[y])         # Create scatter plot of data\n",
    "plt.legend( [Patch(\"b\",\"b\"),Patch(\"orange\",\"orange\")], [\"$-1$\",\"$1$\"], loc=\"lower right\")       # Add legend\n",
    "#plt.set_title(\"Unnormalized\")\n",
    "plt.axis([-2, 2, -2, 2]) \n",
    "#plt.axis([-1, 1, -1, 1])    \n",
    "    \n",
    "# Draw data initial weights for  w=[ 0.5 -4.5]\n",
    "w=np.array([ 0, 1])\n",
    "plt.arrow(0, 0, w[0], w[1], facecolor=\"g\",alpha=.5, width = 0.02, length_includes_head=True, edgecolor=\"None\") \n",
    "plt.plot( [-10,10], -w[0]/w[1] * np.array([-10,10]), c=\"black\", linewidth=1)    # Linear classifier line\n",
    "    \n",
    "# Normalize data and draw scatter\n",
    "x_norm = sklearn.preprocessing.normalize(x)\n",
    "w_norm = sklearn.preprocessing.normalize(w.reshape(1, -1))[0]\n",
    "for i in x_norm:\n",
    "    plt.arrow(0, 0, i[0], i[1], facecolor=\"yellow\",alpha=.5, width = 0.02, length_includes_head=True, edgecolor=\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b03683",
   "metadata": {},
   "source": [
    "**Dataset 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1080ceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array( [[0.76604444, 0.64278761],[ 0.5,0.8660254],[0.17364818,0.98480775],[-0.17364818, 0.98480775],[-0.5, 0.8660254],[-0.76604444, 0.64278761],[-0.76604444, -0.64278761],[-0.5, -0.8660254 ],[-0.17364818, -0.98480775],[ 0.17364818, -0.98480775],[0.5,-0.8660254],[0.76604444,-0.64278761]] )\n",
    "y = np.array([-1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"]=7,7              # Set size of plot\n",
    "    \n",
    "# Creat sublot framework\n",
    "#fig, (plt1, plt2) = plt.subplots(1, 2)\n",
    "    \n",
    "# Create First Plot Draw Scatter of initial Data\n",
    "plt.axhline(0, color=\"gray\", linewidth=.5)\n",
    "plt.axvline(0, color='gray', linewidth=.5)\n",
    "colormap = np.array(['dummy', 'orange', 'blue'])\n",
    "plt.scatter( x[:,0], x[:,1], c=colormap[y]) #c=colormap[y])#, cmap=colormap[y])         # Create scatter plot of data\n",
    "plt.legend( [Patch(\"b\",\"b\"),Patch(\"orange\",\"orange\")], [\"$-1$\",\"$1$\"], loc=\"lower right\")       # Add legend\n",
    "#plt.set_title(\"Dataset 2\")\n",
    "plt.axis([-2, 2, -2, 2]) \n",
    "#plt.axis([-1, 1, -1, 1])    \n",
    "    \n",
    "# Draw data initial weights for  w=[ 0.5 -4.5]\n",
    "w=np.array([ 0, 1])\n",
    "plt.arrow(0, 0, w[0], w[1], facecolor=\"g\",alpha=.5, width = 0.02, length_includes_head=True, edgecolor=\"None\") \n",
    "plt.plot( [-10,10], -w[0]/w[1] * np.array([-10,10]), c=\"black\", linewidth=1)    # Linear classifier line\n",
    "    \n",
    "# Normalize data and draw scatter\n",
    "x_norm = sklearn.preprocessing.normalize(x)\n",
    "w_norm = sklearn.preprocessing.normalize(w.reshape(1, -1))[0]\n",
    "for i in x_norm:\n",
    "    plt.arrow(0, 0, i[0], i[1], facecolor=\"yellow\",alpha=.5, width = 0.02, length_includes_head=True, edgecolor=\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3e7614",
   "metadata": {},
   "source": [
    "<font color=\"red\"> 4/4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281a2772",
   "metadata": {},
   "source": [
    "### Predict Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa24aa1",
   "metadata": {},
   "source": [
    "If the perceptron algorithm were to be run on both datasets, which dataset would it converge on first? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0e0720",
   "metadata": {},
   "source": [
    "<b><font color=\"green\">Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ef9780",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d82d8e1",
   "metadata": {},
   "source": [
    "I predict Dataset 2 will be the first to converge, because Dataset 1 has points further from the weight vector and closer to the decision boundary.\n",
    "This means that the angle between the weight vector and these points are closer to 90 degrees and the angle between them and the decision boundaary\n",
    "are closer to u.\n",
    "\n",
    "Here is the equation for the max updates:\n",
    "\n",
    "$$\n",
    "\\tau\\leq\\dfrac{1}{\\min_{i}|\\langle\\hat{\\mathbf{w}}|\\mathbf{x}_{i}\\rangle|^{2}}=\\dfrac{1}{\\min_{i}|\\cos\\theta_{i}|^{2}}=\\max_{i}|\\cos\\theta_{i}|^{-2}\n",
    "$$\n",
    "\n",
    "In my own words: $\\theta$ is the angle between the point furthest from the ideal weight vector and closes to the decision boundary. Meaning the closer that cosùúÉùëñ gets to 0, the bigger $\\max_{i}|\\cos\\theta_{i}|^{-2}$ will be. Meaning as ùúÉ approaches 90 degrees, the closer cosùúÉ gets to 0. This makes sense because as cosùúÉ gets closer to zero it becomes a fraction, and dividing by a smaller and smaller fraction will make the result(the max updates) bigger and bigger. \n",
    "\n",
    "Here is a quote from the above text from 5.4 that says what I just said, \"Notice that the angle\n",
    "$\\theta_{i}$ between $\\mathbf{x}_{i}$ and $\\mathbf{\\hat{w}}$\n",
    "maximizes $|\\cos\\theta_{i}|^{-2}=\\infty$ when they are perpendicular $(\\theta=\\pm\\pi)$.\n",
    "The angle $\\theta_{i}$ minimizes $|\\cos\\theta_{i}|^{-2}=1$ when\n",
    "they are parallel $(\\theta=0)$. Remember that the linear classifier boundary is\n",
    " always perpendicular to $\\hat{\\mathbf{w}}$ , which is also the same place where $|\\cos\\theta_{i}|^{-2}$ is maximized. What this means\n",
    "is that the maximum number of updates is determined by the \"hardest\n",
    "to classify\" data point that lies closest to the decision boundary.\n",
    "The closer this data point is to the boundary the longer the perceptron algorthim\n",
    "may take to run. Intuitively this makes a lot of sense.\"\n",
    "\n",
    "This means the dataset with a point closer to their ideal boundary will take longer to run. Meaning because dataset 1 has has datapoints closer to the boundary than dataser 2, dataser 1 will take longer to run. Meaning dataset 2 will run faster and converge first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfde5ce0",
   "metadata": {},
   "source": [
    "<font color=\"red\"> 2/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a2d39d",
   "metadata": {},
   "source": [
    "### Theoretical upper bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f76336",
   "metadata": {},
   "source": [
    "For both datasets, calculate the maximum possible number of updates according to the Perceptron Convergence Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82be50bc",
   "metadata": {},
   "source": [
    "<font color=\"orange\"><b>Hint:</b> Notice that the datasets and weight vector have already been normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127195f3",
   "metadata": {},
   "source": [
    "<b><font color=\"green\">Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b4d34c",
   "metadata": {},
   "source": [
    "Because the datasets and weight vector have been normalized we can use this formula to find the upper bound:\n",
    "\n",
    "$$\n",
    "\\tau\\leq\\dfrac{1}{\\min_{i}|\\langle\\hat{\\mathbf{w}}|\\mathbf{x}_{i}\\rangle|^{2}}=\\dfrac{1}{\\min_{i}|\\cos\\theta_{i}|^{2}}=\\max_{i}|\\cos\\theta_{i}|^{-2}\n",
    "$$\n",
    "\n",
    "Dataset 1: \n",
    "\n",
    "The points closest to the decision boundary are: (0.93969262,0.34202014), (-0.93969262,0.34202014), (0.93969262,-0.34202014), (-0.93969262,-0.34202014).\n",
    "\n",
    "These 4 points are equidistant from the decision boundary which lies on the x-axis, orthogonal to the weight vector [0,1].\n",
    "\n",
    "To get the angle ùúÉ between the weight and the point closest to the decision boundary we do 90¬∞ - arctan(0.34202014 / 0.93969262).\n",
    "\n",
    "arctan(0.34202014 / 0.93969262)= 20¬∞\n",
    "\n",
    "90¬∞ - arctan(0.34202014 / 0.93969262) = 70¬∞\n",
    "\n",
    "$$\\tau = |\\cos70¬∞|^{-2} = 8.548632...$$\n",
    "\n",
    "Which we can round up to a max of 9 updates.\n",
    "\n",
    "Dataset 2: \n",
    "\n",
    "The points closest to the decision boundary are: (0.76604444, 0.64278761), (-0.76604444, 0.64278761), (0.76604444, -0.64278761), (-0.76604444, -0.64278761).\n",
    "\n",
    "These 4 points are equidistant from the decision boundary which lies on the x-axis, orthogonal to the weight vector [0,1].\n",
    "\n",
    "To get the angle ùúÉ between the weight and the point closest to the decision boundary we do 90¬∞ - arctan(0.64278761/0.76604444).\n",
    "\n",
    "arctan(0.64278761 / 0.76604444) = 40¬∞\n",
    "\n",
    "90¬∞ - arctan(0.64278761 / 0.76604444) = 50¬∞\n",
    "\n",
    "$$\\tau = |\\cos50¬∞|^{-2} = 2.420276...$$\n",
    "\n",
    "Which we can round up to a max of 3 updates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45987031",
   "metadata": {},
   "source": [
    "<font color=\"red\"> 2.5/2 +0.5 extra credit for rounding the max updates up to the nearest integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7029266f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "01eb5fbf",
    "d3ef8740",
    "1664345e",
    "820631e9",
    "3f865953",
    "218acd4a",
    "0520de94",
    "3e162138",
    "39e8b14e",
    "2f8facc9",
    "d1da780b",
    "7e4bf8e5",
    "0c7f5860",
    "ab9d0560",
    "9e264f10",
    "00b5d8d9",
    "faa2fd4e",
    "6df34bb6",
    "8bb239fa",
    "1d2bc553",
    "646d71fb",
    "394f03ce",
    "d68f990d",
    "d6eed0e9",
    "23caab0a",
    "527f88c4",
    "adbede8d",
    "e07630bc",
    "8822b7fa",
    "f73f55fc",
    "4fda7ace",
    "a205bad1",
    "e7e14534"
   ],
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1a67da76dff0411f8503dc0d63182899": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [
       "widget-interact"
      ],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fcfca24ea9b04decb9c785ba7a838922",
       "IPY_MODEL_b8ff8f18f3b7411595da32d0a28d4082",
       "IPY_MODEL_ea30ed6d84124ff69487fdf991515a36"
      ],
      "layout": "IPY_MODEL_46b31fcacdaf47a095a9d1651abe7df2"
     }
    },
    "38e416edb26a4f75868c6c2c98291537": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46b31fcacdaf47a095a9d1651abe7df2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d67ca800945436f83cb014c184b15ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "776683caadbb467d8e4318d18ddffc9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8154178d8de64d358817fe66f668be06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "b078354b9d04427193cda12ced88da6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8ff8f18f3b7411595da32d0a28d4082": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "FloatSliderView",
      "continuous_update": true,
      "description": "intercept",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_776683caadbb467d8e4318d18ddffc9f",
      "max": 3,
      "min": -2,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": ".2f",
      "step": 0.5,
      "style": "IPY_MODEL_6d67ca800945436f83cb014c184b15ab",
      "value": 0
     }
    },
    "ea30ed6d84124ff69487fdf991515a36": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_b078354b9d04427193cda12ced88da6b",
      "msg_id": "",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Petal_Width = 0.0 Petal_Length + 0.0\n"
        ]
       },
       {
        "data": {
         "image/png": "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\n",
         "text/plain": "<Figure size 576x360 with 1 Axes>"
        },
        "metadata": {
         "needs_background": "light"
        },
        "output_type": "display_data"
       }
      ]
     }
    },
    "fcfca24ea9b04decb9c785ba7a838922": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "FloatSliderView",
      "continuous_update": true,
      "description": "slope",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_38e416edb26a4f75868c6c2c98291537",
      "max": 2,
      "min": -2,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": ".2f",
      "step": 0.5,
      "style": "IPY_MODEL_8154178d8de64d358817fe66f668be06",
      "value": 0
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
